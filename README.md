# PySpark

PySpark is the Python API for Apache Spark, an open source, distributed computing framework  and set of libraries for real-time, large-scale data processing. If you’re already familiar with Python and libraries such as Pandas, then PySpark is a good language to learn to create more scalable analyses and pipelines.

Apache Spark is basically a computational engine that works with huge sets of data by processing them in parallel and batch systems. Spark is written in Scala, and PySpark was released to support the collaboration of Spark and Python. In addition to providing an API for Spark, PySpark helps you interface with Resilient Distributed Datasets (RDDs) by leveraging the Py4j library.

# spark architecture

![alt text](https://avinash333.files.wordpress.com/2019/08/spark-architecture.png)

credit: https://avinash333.com/spark-architecture/


